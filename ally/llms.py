# Define available LLM models and their properties
MODELS = {
    "glm-4.6": {
        "aliases": ["glm", "glm4.6"],
        "vendor": "openrouter",
        "id": "z-ai/glm-4.6",
        "description": "Z.AI's GLM 4.6 model, with 200K context window and improved reasoning, coding, and agent capabilities.",
        "cost_in": 0.50,
        "cost_out": 1.75,
    },
    "gpt-5": {
        "aliases": ["5", "heisen"],
        "vendor": "openai",
        "vision": True,
        "description": "OpenAI's GPT-5 is their best model for coding and agentic tasks across domains.",
        "cost_in": 1.25,
        "cost_out": 10,
        "no_stop": True,
        "temp_min": 1,
        "temp_max": 1,
    },
    "gpt-5-mini": {
        "aliases": ["5m", "heise"],
        "vendor": "openai",
        "vision": True,
        "description": "OpenAI's GPT-5-mini is a faster, cost-efficient version of GPT-5 for well-defined tasks.",
        "cost_in": 0.25,
        "cost_out": 2,
        "no_stop": True,
        "temp_min": 1,
        "temp_max": 1,
    },
    "gpt-5-nano": {
        "aliases": ["5n", "heis"],
        "vendor": "openai",
        "vision": True,
        "description": "OpenAI's GPT-5-nano is the fastest, most cost-efficient version of GPT-5.",
        "cost_in": 0.05,
        "cost_out": 0.4,
        "no_stop": True,
        "temp_min": 1,
        "temp_max": 1,
    },
    # Needs a different "responses API" or something, YAGNI
    # "gpt-5-pro": {
    #     "aliases": ["heisenberg"],
    #     "vendor": "openai",
    #     "vision": True,
    #     "description": "OpenAI's GPT-5-pro is the smartest and most precise model from OpenAI.",
    #     "cost_in": 15,
    #     "cost_out": 120,
    #     "no_stop": True,
    #     "temp_min": 1,
    #     "temp_max": 1,
    # },
    "gpt-oss-120b": {
        "aliases": ["goss"],
        "vendor": "openrouter",
        "vision": True,
        "description": "OpenAI's most powerful open-weight model, fits into an H100 GPU.",
        "cost_in": 0.072,
        "cost_out": 0.28,
    },
    "gpt-oss-20b": {
        "aliases": ["gos"],
        "vendor": "openrouter",
        "vision": True,
        "description": "OpenAI's medium-sized open-weight model for low latency.",
        "cost_in": 0.04,
        "cost_out": 0.15,
    },
    "o3": {
        "aliases": ["op", "grace"],
        "id": "o3-2025-04-16",
        "vendor": "openai",
        "vision": True,
        "description": "OpenAI's strongest reasoning model, with complex reasoning",
        "cost_in": 10,
        "cost_out": 40,
        "no_stop": True,
        "temp_min": 1,
        "temp_max": 1,
    },
    "o4-mini": {
        "aliases": ["om", "fermi"],
        "vendor": "openai",
        "vision": True,
        "description": "OpenAI's faster, cheaper reasoning model.",
        "cost_in": 3,
        "cost_out": 12,
        "no_stop": True,
        "temp_min": 1,
        "temp_max": 1,
    },
    "gpt-4": {
        "aliases": ["4", "emmy"],
        "vendor": "openai",
        "vision": True,
        "id": "gpt-4.1",
#        "id": "gpt-4.1-2025-04-14",
#        "id": "gpt-4o-2024-11-20",
        "description": "OpenAI's GPT-4.1 is an advanced multimodal model.",
        "cost_in": 2,
        "cost_out": 8,
    },
    "gpt-4.1-mini": {
        "aliases": ["4m", "dav", "davinci"],
        "vendor": "openai",
        "vision": True,
        "description": "OpenAI's GPT-4.1 mini is a cost-efficient model.",
        "cost_in": 0.40,
        "cost_out": 1.6,
    },
    "claude-opus": {
        "aliases": ["co", "claudo", "claude-4-opus"],
        "vendor": "anthropic",
        "vision": True,
        "id": "claude-opus-4-1-20250805",
#        "id": "claude-opus-4-20250514",
#        "id": "claude-3-7-sonnet-latest",
        "description": "Claude 4.1 Opus is Anthropic's strongest large model.",
        "cost_in": 15,
        "cost_out": 75,
    },
    "claude": {
        "aliases": ["c", "claude-4-sonnet", "claude-sonnet"],
        "vendor": "anthropic",
        "vision": True,
        "id": "claude-sonnet-4-5-20250929",
#        "id": "claude-sonnet-4-20250514",
#        "id": "claude-3-7-sonnet-latest",
        "description": "Claude 4.5 Sonnet is Anthropic's latest and strongest model, a mid-size model.",
        "cost_in": 3,
        "cost_out": 15,
    },
    # "claude": {
    #     "aliases": ["c", "claud", "claude-3.5"],
    #     "vendor": "anthropic",
    #     "vision": True,
    #     "id": "claude-3-5-sonnet-latest",
    #     "description": "Claude 3.5 Sonnet is Anthropic's strong and reliable model.",
    #     "cost_in": 3,
    #     "cost_out": 15,
    # },
    "claude-3.7": {
        "vendor": "anthropic",
        "aliases": ["claudia"],
        "vision": True,
        "id": "claude-3-7-sonnet-latest",
        "description": "Claude 3.7 Sonnet is strong at role-playing.",
        "cost_in": 3,
        "cost_out": 15,
    },
    "claude-haiku": {
        "aliases": ["i", "clia", "claude-3.5-haiku"],
        "vendor": "anthropic",
        "vision": True,
        "id": "claude-3-haiku-20240307",
        "description": "Claude 3 Haiku is Anthropic's fastest and most affordable model.",
        "cost_in": 0.25,
        "cost_out": 1.25,
    },
    "gemini-3-pro": {
        "aliases": ["gemi"],
        "vendor": "google",
        "vision": True,
        "api_key": "GOOGLE_API_KEY",
        "id": "gemini-3-pro-preview",
        "description": "Google's strongest Gemini model with a 1 million context window and 64K output.",
        "cost_in": 2,
        "cost_out": 12,
    },
    "gemini-2.5-pro": {
        "aliases": ["gemmi", "gemmi-paid", "gemini", "gp"],
        "vendor": "google",
        "vision": True,
        "api_key": "GOOGLE_API_KEY",
        "id": "gemini-2.5-pro",
        "description": "Google's strong Gemini model with a 1 million context window and 64K output.",
        "cost_in": 1.25,
        "cost_out": 10,
    },
    # "gemini-2.5-pro-free": {
    #     "aliases": ["gemmi-free", "gemini-free"],
    #     "vendor": "google",
    #     "vision": True,
    #     "api_key": "GOOGLE_API_KEY_FREE",
    #     "id": "gemini-2.5-pro-exp-03-25",
    #     "description": "Google's strong Gemini model with a 1 million context window and 64K output.",
    #     "cost_in": 0,
    #     "cost_out": 0,
    # },
    # "gemini-2.5-pro-openrouter": {
    #     "aliases": ["gemmi-openrouter"],
    #     "vendor": "openrouter",
    #     "vision": True,
    #     "id": "google/gemini-2.5-pro-exp-03-25:free",
    #     "description": "Google's strong Gemini model with a 1 million context window and 64K output.",
    #     "cost_in": 0,
    #     "cost_out": 0,
    # },
    "gemini-2.5-flash": {
        "aliases": ["flashi"],
        "id": "models/gemini-2.5-flash",
        "vendor": "google",
        "vision": True,
        "description": "Google's fast thinking model with a 1 million context window.",
        "cost_in": 0.15,
        "cost_out": 0.6,
    },
    "gemini-2.0-flash-lite": {
        "aliases": ["lite"],
        "vendor": "google",
        "vision": True,
        "description": "Google's fastest model with a 1 million context window.",
        "cost_in": 0.075,
        "cost_out": 0.3,
    },
    "gemini-2.0-flash": {
        "aliases": ["gf", "flasho"],
        "vendor": "google",
        "vision": True,
        "description": "Google's fast model with a 1 million context window.",
        "cost_in": 0.1,
        "cost_out": 0.4,
    },
    "sonar-reasoning-pro": {
        "aliases": ["sageri"],
        "vendor": "perplexity",
        "description": "Perplexity's Sonar Resoning Pro model, with 127K context and online access.",
        "cost_req": 5,
        "cost_in": 2,
        "cost_out": 8,
    },
    "sonar-reasoning": {
        "aliases": ["sonari"],
        "vendor": "perplexity",
        "description": "Perplexity's Sonar Resoning model, with 127K context and online access.",
        "cost_req": 5,
        "cost_in": 1,
        "cost_out": 5,
    },
    "sonar-pro": {
        "aliases": ["sagi"],
        "vendor": "perplexity",
        "description": "Perplexity's Sonar Pro model, with 300K context and online access.",
        "cost_req": 5,  # per thousand
        "cost_in": 3,
        "cost_out": 15,
    },
    "sonar": {
        "aliases": ["sona"],
        "vendor": "perplexity",
        "description": "Perplexity's Sonar model, with 127K context and online access.",
        "cost_req": 5,
        "cost_in": 1,
        "cost_out": 1,
    },
    "grok2": {
        "vendor": "xai",
        "aliases": ["grokko"],
        "id": "grok-2-vision",
        "description": "xAI's Grok 2 Vision model, with 32K context and a sense of humour",
        "cost_in": 2,
        "cost_out": 10,
    },
    "grok3": {
        "vendor": "xai",
        "aliases": ["rocki"],
        "id": "grok-3-beta",
        "description": "xAI's Grok 3 model, with 128K context and a sense of humour",
        "cost_in": 3,
        "cost_out": 15,
    },
    "grok4": {
        "vendor": "xai",
        "aliases": ["grok", "ani", "anni"],
        "id": "grok-4-0709",
        "description": "xAI's Grok 4 model, with 256K context and a sense of humour",
        "cost_in": 3,
        "cost_out": 15,
        "no_stop": True,
    },
    "grok3-mini": {
        "vendor": "xai",
        "aliases": ["gokk", "g3mini"],
        "id": "grok-3-mini",
        "description": "xAI's Grok 3 Mini model, with 128K context and a sense of humour",
        "cost_in": 0.3,
        "cost_out": 0.5,
        "no_stop": True,
    },
    "grok4-fast": {
        "vendor": "xai",
        "aliases": ["gok", "g4f"],
        "id": "grok-4-fast-non-reasoning",
        "description": "xAI's Grok 4 Fast Non-Reasoning model, with 2M context and a sense of humour",
        "cost_in": 0.2,
        "cost_out": 0.5,
        "no_stop": True,
    },
    "grok-code-fast": {
        "vendor": "xai",
        "aliases": ["groc", "gc"],
        "id": "grok-code-fast-1",
        "description": "xAI's Grok Code Fast model, optimized for coding tasks with 2M context",
        "cost_in": 0.2,
        "cost_out": 1.5,
        "no_stop": True,
    },
    # "deepseek-chat-free": {
    #     "vendor": "openrouter",
    #     "id": "deepseek/deepseek-chat-v3-0324:free",
    #     "description": "deepseek-chat points to DeepSeek-V3",
    #     "cost_in": 0.27,
    #     "cost_out": 1.10,
    # },
    # "deepseek-reasoner-free": {
    #     "vendor": "openrouter",
    #     "id": "deepseek/deepseek-r1-0528:free",
    #     "description": "deepseek-reasoner points to DeepSeek-R1",
    #     "cost_in": 0.55,
    #     "cost_out": 2.19,
    # },
    "deepseek-v3": {
        "aliases": ["dese"],
        "vendor": "openrouter",
        "id": "deepseek/deepseek-chat-v3-0324",
        "description": "DeepSeek-V3",
        "cost_in": 0,
        "cost_out": 0,
    },
    "deepseek-chat": {
        "aliases": ["desee"],
        "vendor": "deepseek",
        "id": "deepseek-chat",
        "description": "deepseek-chat points to DeepSeek-V3.1",
        "cost_in": 0.27,
        "cost_out": 1.10,
    },
    "deepseek-reasoner": {
        "aliases": ["deseri"],
        "vendor": "deepseek",
        "id": "deepseek-reasoner",
        "description": "deepseek-reasoner points to DeepSeek-R1",
        "cost_in": 0.55,
        "cost_out": 2.19,
    },
    "llama-3.3-70b-free": {
        "aliases": ["ellen"],
        "vendor": "openrouter",
        "id": "meta-llama/llama-3.3-70b-instruct:free",
        "description": "Llama 3.3 70B",
        "cost_in": 0,
        "cost_out": 0,
    },
    "llama-4-scout": {
        "aliases": ["scout", "skout"],
        "vendor": "openrouter",
        "id": "meta-llama/llama-4-scout",
        "description": "Llama 4 Scout",
        "cost_in": 0,
        "cost_out": 0,
    },
    "llama-4-maverick": {
        "aliases": ["maverick", "mavi"],
        "vendor": "openrouter",
        "id": "meta-llama/llama-4-maverick",
        "description": "Llama 4 Maverick",
        "cost_in": 0,
        "cost_out": 0,
    },
    "gemma-3-27b-free": {
        "aliases": ["gemma-free"],
        "vendor": "openrouter",
        "id": "google/gemma-3-27b-it:free",
        "description": "Gemma 3 27B",
        "cost_in": 0,
        "cost_out": 0,
    },
    "gemma-3-27b": {
        "aliases": ["gemma"],
        "vendor": "openrouter",
        "id": "google/gemma-3-27b-it",
        "description": "Gemma 3 27B",
        "cost_in": 0,
        "cost_out": 0,
    },
    "gemma-3-12b-free": {
        "aliases": ["gemma-12b-free"],
        "vendor": "openrouter",
        "id": "google/gemma-3-12b-it:free",
        "description": "Gemma 3 12B",
        "cost_in": 0,
        "cost_out": 0,
    },
    "gemma-3-12b": {
        "aliases": ["gemma-12b"],
        "vendor": "openrouter",
        "id": "google/gemma-3-12b-it",
        "description": "Gemma 3 12B",
        "cost_in": 0,
        "cost_out": 0,
    },
    "gemma-3-4b-free": {
        "aliases": ["gemma-4b-free"],
        "vendor": "openrouter",
        "id": "google/gemma-3-4b-it:free",
        "description": "Gemma 3 4B",
        "cost_in": 0,
        "cost_out": 0,
    },
    "gemma-3-4b": {
        "aliases": ["gemma-4b"],
        "vendor": "openrouter",
        "id": "google/gemma-3-4b-it",
        "description": "Gemma 3 4B",
        "cost_in": 0,
        "cost_out": 0,
    },
    "gemma-3-1b-free": {
        "aliases": ["gemma-1b-free"],
        "vendor": "openrouter",
        "id": "google/gemma-3-1b-it:free",
        "description": "Gemma 3 1B",
        "cost_in": 0,
        "cost_out": 0,
    },
    "gemma-3-1b": {
        "aliases": ["gemma-1b"],
        "vendor": "openrouter",
        "id": "google/gemma-3-1b-it",
        "description": "Gemma 3 1B",
        "cost_in": 0,
        "cost_out": 0,
    },
    "qwq-32b": {
        "aliases": ["qwen"],
        "vendor": "openrouter",
        "id": "qwen/qwq-32b:free",
        "description": "Qwen: QwQ 32B (free)",
        "cost_in": 0,
        "cost_out": 0,
    },
    # "eva-qwen2.5-72b": {
    #     "aliases": ["eva"],
    #     "vendor": "openrouter",
    #     "id": "eva-unit-01/eva-qwen-2.5-72b",
    #     "description": "EVA Qwen2.5 72B",
    #     "cost_in": 0.9,
    #     "cost_out": 1.2,
    # },
    "mistral-large": {
        "aliases": ["misti"],
        "vendor": "openrouter",
        "id": "mistralai/mistral-large-2411",
        "description": "Mistral Large 2411",
        "cost_in": 2,
        "cost_out": 6,
    },
    # "venice-uncensored-free": {
    #     "aliases": ["veni"],
    #     "vendor": "openrouter",
    #     "id": "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
    #     "description": "Venice: Uncensored (free)",
    #     "cost_in": 0,
    #     "cost_out": 0,
    # },
    "venice-uncensored": {
        "aliases": ["veni"],
        "vendor": "venice",
        "description": "Venice: Uncensored",
        "cost_in": 0.5,
        "cost_out": 2,
    },
    "kimi": {
        "aliases": ["kimi-k2"],
        "vendor": "openrouter",
        "id": "moonshotai/kimi-k2-0905",
        "description": "MoonshotAI: Kimi K2 0905",
        "cost_in": 0.39,
        "cost_out": 1.9,
    }
}

# default_model = "claude"
# default_model_small = "gemini-2.0-flash"
default_model = "gpt-5"
default_model_small = "gpt-5-mini"

SERVICES_BROKEN = ["openai", "anthropic"]

MODEL_FALLBACKS = {
    "*:*": "google:gemini-2.0-flash",

    # OpenAI models
    "openai:gpt-5": "google:gemini-3-pro",
    "openai:gpt-5-mini": "google:gemini-2.5-flash",
    "openai:gpt-5-nano": "google:gemini-2.0-flash-lite",
    "openai:o3": "google:gemini-3-pro",
    "openai:o4-mini": "google:gemini-2.5-pro",
    "openai:gpt-4": "google:gemini-2.5-pro",
    "openai:gpt-4.1-mini": "google:gemini-2.5-flash",
    "openai:*": "google:gemini-2.0-flash",

    # Anthropic models
    "anthropic:claude-opus": "google:gemini-3-pro",
    "anthropic:claude": "google:gemini-2.5-pro",
    "anthropic:claude-3.7": "google:gemini-2.5-pro",
    "anthropic:claude-haiku": "google:gemini-2.0-flash-lite",
    "anthropic:*": "google:gemini-2.0-flash",

    # OpenRouter models
    "openrouter:glm-4.6": "google:gemini-2.5-flash",
    "openrouter:gpt-oss-120b": "google:gemini-2.0-flash",
    "openrouter:gpt-oss-20b": "google:gemini-2.0-flash",
    "openrouter:deepseek-v3": "google:gemini-2.5-pro",
    "openrouter:llama-3.3-70b-free": "google:gemini-2.0-flash",
    "openrouter:llama-4-scout": "google:gemini-2.5-flash",
    "openrouter:llama-4-maverick": "google:gemini-2.5-flash",
    "openrouter:gemma-3-27b-free": "google:gemini-2.0-flash",
    "openrouter:gemma-3-27b": "google:gemini-2.0-flash",
    "openrouter:gemma-3-12b-free": "google:gemini-2.0-flash-lite",
    "openrouter:gemma-3-12b": "google:gemini-2.0-flash-lite",
    "openrouter:gemma-3-4b-free": "google:gemini-2.0-flash-lite",
    "openrouter:gemma-3-4b": "google:gemini-2.0-flash-lite",
    "openrouter:gemma-3-1b-free": "google:gemini-2.0-flash-lite",
    "openrouter:gemma-3-1b": "google:gemini-2.0-flash-lite",
    "openrouter:qwq-32b": "google:gemini-2.0-flash-lite",
    "openrouter:mistral-large": "google:gemini-2.0-flash",
    "openrouter:kimi": "google:gemini-2.0-flash",
    "openrouter:*": "google:gemini-2.0-flash",

    # Perplexity models
    "perplexity:sonar-reasoning-pro": "google:gemini-2.5-pro",
    "perplexity:sonar-reasoning": "google:gemini-2.5-flash",
    "perplexity:sonar-pro": "google:gemini-2.5-pro",
    "perplexity:sonar": "google:gemini-2.0-flash",
    "perplexity:*": "google:gemini-2.0-flash",

    # xAI models
    "xai:grok2": "google:gemini-2.0-flash",
    "xai:grok3": "google:gemini-2.0-flash",
    "xai:grok4": "google:gemini-3-pro",
    "xai:grok3-mini": "google:gemini-2.0-flash",
    "xai:grok4-fast": "google:gemini-2.0-flash",
    "xai:grok-code-fast": "google:gemini-2.5-pro",
    "xai:*": "google:gemini-2.0-flash",

    # Deepseek models
    "deepseek:deepseek-chat": "google:gemini-2.5-flash",
    "deepseek:deepseek-reasoner": "google:gemini-2.5-pro",
    "deepseek:*": "google:gemini-2.0-flash",

    # Venice models
    "venice:venice-uncensored": "google:gemini-2.0-flash",
    "venice:*": "google:gemini-2.0-flash",
}
