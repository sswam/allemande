# Devlog: Week of 2023-09-25 to 2023-10-01

This week was focused on improving Ally Chat's summarization capabilities, exploring email integration and health-monitoring app ideas, and refining web content processing tools.

## Key Achievements

*   **Improved Chat Summarization**: Significantly enhanced the two-stage chat summarization script for better context and organization.
*   **Explored New Ideas**: Brainstormed and documented ideas for email integration and a health monitoring application.
*   **Refined Web Content Processing**: Improved tools for fetching and cleaning web content, including a new testing script.
*   **Bug fixes**: Fixed a bug in pandoc-dump and improved regex in pandoc-dump-clean

## Enhanced Chat Summarization

I've been working on improving how Ally Chat summarizes conversations. The `chat-summary.sh` script now uses a two-stage process. First, it summarizes the new chat messages using Claude Instant (Clia), a fast and cheap model. Then, it combines this new summary with the previous summary and the mission context, using the more powerful Claude model (Claud) to produce a final, consolidated summary. This final summary is reorganized by topic, removing duplicate information and aiming for a concise and well-structured overview of the conversation. This is still experimental, with a few TODOs relating to topic modeling and message counts.

## Exploring New Ideas

I spent some time brainstorming new feature ideas. I've added a new idea file for email integration, `ideas/email.txt`. The main concept is to enable AI agents within Ally Chat to send and receive emails, essentially acting as personal secretaries. This could potentially integrate with other communication services, like other chat apps, via libpurple.

Another idea is a health monitoring app, detailed in `ideas/health-monitor-app.txt`. This app would listen for signs of distress during sleep (and potentially while awake), detecting events like heart attacks, strokes, or falls. If the app detects a problem and the user doesn't respond, it would alert emergency contacts or services.

## Refined Web Content Processing

I've made several improvements to the tools used for processing web content. The `pandoc-dump` script now cleans up the HTML *before* converting it to Markdown, using a new `pandoc-dump-clean-html` script. This new script currently focuses on cleaning up MediaWiki HTML (like Wikipedia), removing navigation elements and other unwanted content.

I've also created `web-summary-test.sh`, a new script for analyzing web pages. It downloads the content, summarizes it using different AI models (Claude Instant, Claude, and GPT-4), and calculates statistics like character, word, and token counts. This helps in estimating the costs associated with summarizing web content using different AI models, and in improving the summarization prompts. Also I made some minor fixes to the `wg` ("web get") tool which is used in the new script.

The `pandoc-dump-clean` script also saw some improvements, including updated regular expressions to better remove query strings from URLs and remove Markdown link titles.

## Bug fixes

I fixed a bug in `pandoc-dump` which was to call the `single-blank-lines.pl` script twice.

## Other

I also fixed a stray "TODO" comment in the code, and added an example of GPT-4 making typos to `bugs/gpt-4-typos.txt`.
