# Devlog: Week of 2024-09-23 to 2024-09-29

This week has been a whirlwind of activity, marked by significant improvements and feature additions across several areas of the project. There was a general push towards code cleanup, adding new features, and building out new components, especially focused on improving integration with LLMs and streamlining various workflows. As always, this log won't invent anything and will only describe the work that is evident in the provided commits!

## Key Highlights

*   **`ally` Library Overhaul:** Significant refactoring to use the `ally` library for improved input/output handling, dependency management, and modularity.
*   **Bash Scripting Enhancements:** Added new utility scripts, improved existing ones, and added new BATS tests, enhancing scripting capabilities across the project.
*   **LLM Integration:** Several new tools and improvements to existing LLM-based scripts were introduced, providing better flexibility.
*   **Image Processing Tools:** New tools for image generation, debugging, and metadata handling were added, enabling better workflow when working with images in the project.
*   **Lazy Loading Implementation:** A lazy loading system implemented in the `ally` library, designed to improve performance by deferring module loading until it's absolutely necessary.

## Detailed Breakdown

### `ally` Library Refinements

A major focus this week was on integrating and refining the `ally` library, which serves as a foundational component for many scripts and tools.

*   **Refactored Input/Output:** Refactored codebase, and in particular the `main.py` module, to use the `ally` library for `istream` and `ostream` handling. This provides more consistent and flexible I/O across the project. This included renaming the `input` function in `tty.py` to `get` to align with the `ally` library conventions.
*   **Module Relocation:** Moved `terminal.py` functionality into a new `tty.py` module within the `ally` package, consolidating terminal-related utilities.
*   **Lazy Loading Implementation:** Introduced a `lazy` loading mechanism for Python modules within the `ally` library. This allows deferred loading of modules until they are actually needed, improving startup time and reducing memory footprint. The `lazy` module includes a `LazyProxy` class and supporting functions for managing lazy-loaded modules and symbols.
*   **Dynamic Variable Referencing:** Added a new module for dynamic variable referencing, allowing the creation of references to variables, object attributes, dictionary items, and array items for dynamic manipulation.
*  **Improved File Handling** The "ally" library got a "locate_file" subroutine in "ally.sh" that will "wich" for a file.
*  **Moving `ref` to `future`** The `ref` module was moved to the `future` directory.

### Bash Scripting

Continued improvements and additions were made to Bash scripts throughout the project.

*   **`opts` Script Improvements:** The `opts` script was updated to improve usage output formatting, skipping lines starting with ". " and squeezing blank lines.
*   **`hello_sh.sh` Enhancements:** The `hello_sh.sh` script was enhanced to include AI processing options for shopping lists.
* **Automatic Options Help** Automatic options help now uses `opts_help.py` instead of internal code.
*   **New Helper Script:** New "one-liner" LLM scripts were added, `1sp` (single sentence) and `1wp` (single word) for simpler interactions.
*   **Test Enhancements** the `test_helper` link now has BATS support.
*  **Removed BASH strictness enforcement.**
*  **More AI Guidance** The "hello_sh" was further enhanced with more notes for the AI.
*  **Canon Script** The canon script was adjusted to create symlinks for canonical naming.

### LLM Integration

The project saw continued enhancements in its use of LLMs, expanding the tools and integration points.

*   **Combine Script:** Added a new script `combine.sh` for merging similar inputs using an LLM, enabling the generation of more comprehensive and coherent results.
*   **Critique Script Improvements:** The critique script received improvements to its prompts to focus on identifying errors. The 'v' command was removed from tee output.
*   **File Handlng improvements.** The `code_modify` helper was implemented to refactor common functions into `ally.sh`.
*   **GPT enhancements** LLM support was improved.
*   **Translation Script:** A new script (`translate.sh`) was implemented to convert files from one format to another. It leverages the `create.sh` script for the actual translation and supports various parameters for customization.
*   **New Models** support for Perplexity and Google AI models was added.
*   **Dynamic Module Loading:** Implemented dynamic module loading for LLM APIs, improving performance by loading modules only when needed.
*  **Timing option** Added for LLM requests.
*  **Usage Updates** Code was snipped from opts.sh since the LLM support is not longer there.
*  **Cleanups** Unused Claude advice was removed, and the default "cheap" small model was renamed in the config to "small".

### Image Processing

New image processing tools and capabilities were added to the project.

*   **Stable Diffusion WebUI API Client:** Implemented an async client for generating images using the Stable Diffusion WebUI API. The client supports various parameters such as prompts, negative prompts, seed, sampler, scheduler, steps, CFG scale, width, and height.
*   **Image Debugging Scripts:** Added `image_debug.sh` for parameter analysis of images, and `qiv-command` for performing custom actions within the `qiv` image viewer.
*   **Image Metadata Processing:** Implemented `stamp.py` for processing image metadata, including extracting, inserting, erasing, and converting image formats while preserving metadata.
* **Image Viewer enhancements** `qiv-command` was enhanced to add the 'O' option to move images to output folder, and to use `lessit` wrapper for popup terminals.
* **Image Debugging** Improved Image Viewing and Debugging Scripts.
* SDXL Integration** Added.
* Image Debugger: New SDXL text-to-image generation demo script and debugging tools.

### New Modules and Utilities

*   **Time Utilities:**  Added `describe-interval.py` and `sleep-log` for describing time intervals and logging sleep durations.
*   **Unprompted Dump:** Added a script to transform `[sets]` markups to variable displays, called `unprompted_dump.py`
*   **Text Processing:**  Added a `squeeze` function to compress whitespace in text.
*   **Reverse Lines** A python script was added to reverse lines of text and is BATS tested.
*  **Code Statistics** A new tool, `code-language.py`, was added to determine the code language of a file based on its extension.
* **Swapping files** A simple BATS script was created to swap file contents, and more functionality was added to support hard links.

### Codebase Reorganization

*   **File Relocation:** Moved several scripts, including `improve.sh` and `create.sh` from the `code` directory to `llm`, to better reflect their broader utility beyond code-specific tasks. Also moved the utility `reverse_lines.py` from `code/gen_tests` to the main `code` directory, and relocated test files accordingly.

### Test Automation
* Lots of new BATS tests were added, including new BATS tests that support AI, but require a separate flag to run.

### Web-related Scripts

A new script was added for use with web pages.

*   **`web_summary`:** A script to fetch webpage and provide summarization.

## Specific Tasks
* TODO comments can now be processed for TODOs with a shell script.
* C code got an update, in the form of a 'hello world'.

## Challenges Faced

*   **Maintaining Code Style:** Ensuring consistent code style across different languages and script types continues to be a challenge, and there was a lot of effort expended trying to standardize coding styles.

## Looking Ahead

The project is rapidly evolving, and I continue to embrace new tools and techniques to improve functionality, performance, and maintainability. There is a plan to continue to focus on enhancing LLM integration, refining the `ally` library, and addressing code consistency and performance issues. In particular, there will be a focus on:

*   **Streamlining** Streamlining CLI tools and standardizing workflows for LLM-based tasks.
*   **Experimenting** Experimenting with lazy loading and module proxies.

I am especially excited about the prospect of leveraging dynamic loading and dependency management for future development.
