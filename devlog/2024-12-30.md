# Devlog: Week of 2024-12-30 to 2025-01-05

This week, I focused on improving chat agent personalities, system monitoring, and some under-the-hood tweaks to our LLM configuration.

## Key Achievements:

*   **Improved Chatbot Personality Descriptions:** Gave the AI chatbot agents, like Ally, Barbie, and Callam, more distinct and engaging personality descriptions.
*   **Added System Resource and Network Monitoring Script:** Implemented a new script to monitor system resources (disk, memory, load) and network connectivity, providing early warnings for potential issues.
*   **Simplified Chat System Messages:** Streamlined the system messages used to guide the AI in conversations, aiming for clearer and more concise interactions.
*   **Tuned LLM Generation Parameters:** Refactored and tuned the LLM (llama-cpp-python) generation parameters to reduce repetition and improve the overall quality of responses.
*   **Switched `brain.sh` to Default LLM Config:** Updated the `brain.sh` script to use the default LLM configuration, moving away from the experimental settings.
*   **Dependency Management:** Switched to a local fork of `llama-cpp-python` instead of relying on the pip package.
*   **Fixed Bash Scripting Issue:** Added `local` keyword to variable declarations in `hello-sh` bash function.

## Detailed Breakdown:

### Enhanced Chatbot Personalities

The personality descriptions for several AI chatbot agents were refined. For example, Ally's description was changed from "Please be creative, and try not to repeat what you've said before unless it's necessary" to "You are Ally. Ally is creative and talkative. You always say something interesting." Similar changes were made to Barbie and Callam, emphasizing their unique traits and encouraging more engaging responses. I also removed the explicit "try not to repeat" instruction, hoping to make the bots sound more natural.

### System Resource and Network Monitoring

A new `monitor.sh` script was added to provide basic system monitoring. This script checks disk space usage, system load average, memory usage, and network connectivity by pinging Google's DNS server (8.8.8.8). Configurable thresholds are in place to trigger warnings when resource usage exceeds acceptable levels. I added a verbose mode and bumped the default memory usage threshold, also adding `INFO:` and `WARNING:` prefixes for better clarity. This will help me proactively identify and address potential performance bottlenecks.

### Streamlined Chat System Messages

The system messages used to prime the AI for chat interactions were simplified. I removed the "try not to repeat" phrasing, as it seemed to be hindering the AI's ability to respond naturally. Also, the script now strips backticks from chat history text to avoid messing with image generation.

### LLM Parameter Tuning and Configuration

I spent some time refactoring and tuning the generation parameters for the Llama LLM. The goal was to reduce repetition in the AI's responses and improve overall conversational flow. The configuration has been made more DRY (Don't Repeat Yourself) to be more maintainable. I did also simplify the "sequence breaker" list to *only* double newlines.

### Default LLM Config for `brain.sh`

The `brain.sh` script, which drives the core chat functionality, was updated to use the `default.yaml` LLM configuration file instead of the `experiment.yaml` config. This reflects a shift towards a more stable and well-tested configuration for general use.

### Dependency Management

To gain more control over the llama-cpp-python library, I switched to using a local fork instead of the pip package. This allows for easier customization and debugging.

### Bash Scripting Fix

A minor but important fix was made to the `hello-sh` bash function to declare local variables.
