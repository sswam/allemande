# Devlog: Week of 2025-01-06 to 2025-01-12

This week I focused on adjusting our LLM-powered agents and fixing a few minor issues.

## Key Achievements:

*   **Improved Local Model Personalities:** Tweaked the personalities of the local AI model characters (Ally, Barbie, Callam) to make them more engaging and consistent.
*   **Smoother LLM Output:** Adjusted parameters related to sequence breaking and "dryness" in the Llama LLM configuration to improve the flow and reduce repetition.
*   **Fixed Gemini Model Codes:** Corrected the codes for Gemini models to "gp" and "gf" in our internal scripts, avoiding potential confusion.

## Detailed Breakdown:

### Adjusting Local Model Personalities

I spent some time iterating on the system prompts that define the personalities of our locally-hosted AI agents, specifically Ally, Barbie, and Callam. The goal was to make them more distinct and consistent in their responses. I moved all system prompts to the same position for consistency and removed redundant phrasing from the prompt text, simplifying them. For example, I changed Ally's prompt from "You are Ally. Ally is creative and talkative. You always say something interesting." to "You are Ally. Ally is creative and talkative." Hopefully, these subtle adjustments will lead to more natural and engaging conversations with these characters. Callam speaks like a pirate, so he requires some extra care...

### Tuning LLM Output

To improve the quality of text generated by our Llama LLM, I experimented with parameters that control repetition and output "dryness". I changed the sequence breaker to "-----" in the LLM's default configuration, which seems to provide better conversational flow. I also tweaked the "dryness" parameters, adjusting `allowed_length`, `multiplier`, and `base` to encourage more varied and interesting responses. The right balance is tricky to find, so I may be revisiting this in the future.

### Gemini Model Code Correction

A small but important fix was made to our internal scripting regarding the Gemini models. I corrected the model codes from "g" and "f" to "gp" and "gf", respectively. This change ensures that the correct models are selected when specifying them in the chat app, preventing any potential errors or unexpected behavior. It's important to keep things tidy, even in my messy scripts.
