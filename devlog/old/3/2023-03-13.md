## Devlog: 2023-03-13 to 2023-03-19

**Summary:**

*   Initial release of Point-Alpaca weights.
*   Implemented XOR-based encryption/decryption scripts for weight distribution.
*   Created a basic command-line chat interface for interacting with the model.

**Details:**

This week was all about getting the initial release of Point-Alpaca out the door.  The main goal was to provide a way for users with access to the original LLaMA weights to apply our fine-tuning and get a working Alpaca-like model.  Since we can't directly distribute the fine-tuned weights themselves due to licensing, we went with a differential approach.

*   **Weight Release and Encryption/Decryption:** The core of the release is the set of "encrypted" files hosted on Digital Ocean Spaces.  The "encryption" is really just a simple XOR operation against the original LLaMA weights.  To facilitate this, we wrote two Python scripts, `encrypt.py` and `decrypt.py`.  `encrypt.py` takes the original LLaMA weight file and a "key" file (in this case, our fine-tuned weights) and outputs an XORed, "encrypted" version, prepended with a SHA256 checksum. `decrypt.py` does the reverse, taking the encrypted file and the original weight file to reconstruct the fine-tuned weights, also checking the checksum to verify data integrity.  We also added `.gitignore` files to `original`, `encrypted` and `result` directories to prevent accidentally committing the original weights, encrypted files or resulting model files. Also, `.gitignore` was slightly modified to avoid tracking of decrypted source code and MacOS `.DS_Store` files. The `decrypt.py` script was updated to correctly remove the checksum and ".enc" extension from the output file name.

*   **Command-Line Chat Interface (`chat.py`):**  To make it easier for people to test the model, we put together a very basic command-line chat interface using `chat.py`. This script loads the model using the `transformers` library and then enters a loop, taking user input, formatting it as a prompt, generating a response from the model, and printing the response.  It also keeps track of the conversation history. We made some updates to inference code and pointed it to right directory to get model from.

*   **`README.md` Updates:**  We created the initial `README.md` to explain what Point-Alpaca is, how to apply the diffs, and how to run the basic chat interface.  We added a small image of alpaca, and updated the instructions to use `wget` instead of `curl` for downloading the encrypted files and also updated the URL's in `filelist.txt`.

*   **Dependencies:** We also added `requirements.txt` file with all the necessary dependencies, including a specific commit hash for the `transformers` library, torch, sentencepiece, tokenizers, wandb and accelerate.

Overall, it was a hectic week focused on getting the project into a releasable state. There's definitely room for improvement in the chat interface and the encryption process, but it's a start.
