## Devlog: Week of 2023-05-01 to 2023-05-07

**Summary:**

*   Implemented basic web chat functionality with Nginx and HAProxy configuration.
*   Refactored the code base for improved organization and maintainability.
*   Continued integration with Anthropic's Claude API, creating a new Python module with model constants and fixing bugs.
*   Added a script to create flashcards from text using AI.
*   Enhanced i3 window manager tools and created utility scripts.
*   Created basic setup scripts for static website.
*   Added documentation and refined build process.
*   Made some adjustments related to code style, stability, and UX.

**Details:**

This week was focused on getting the basic web chat functionality working and deployed, as well as refactoring and adding several utility scripts.

A large chunk of the week was spent setting up the web-facing services.  I created Nginx configurations for the `allemande.ai`, `chat.allemande.ai`, and `rooms.allemande.ai` subdomains and local variants, routing traffic appropriately to backend services. Then a HAProxy configuration was set up to serve SSL traffic using SNI and route based on hostname, also including the initial SSL configurations and HTTP-to-HTTPS redirects.

The core AI interaction saw some significant movement. The first goal was to integrate the Anthropic's Claude API, including setting up a new Python module `anthropic/claude.py`. The default temperature, token limit, and models are now specified as constants. Also message handling has been improved to provide chat history to Claude. I tested Claude's coding abilities a little with, `anthropic/test-claude-code.py`.

The local audio pipeline was adjusted, increasing the default energy threshold for microphone input and lowering the confidence level that whisper requires, reflecting some tweaking to account for background noise. The audio input and output now run under a file mutex.

General code refactoring and addition of new scripts to automate common tasks occupied the middle of the week. Most notably, the OpenAI folder was renamed `llm` to reflect support for different Language Models, which involved also modifying the shell scripts and updating the environment configuration.

The build process was changed to have separate install and install-dev targets. Also there was an addition of a few helper scripts for `i3` window manager, to be added to `PATH`.

Finally, a flashcards generation script, `table/llm-flashcards`, was added, using the LLM to create cards in the `.rec` format. As part of this, a sample of Conventional Commits flashcards were included.
