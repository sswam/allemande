### Fighting AI Gatekeepers with a Simple Crypto Trick

This week was all about releasing the fine-tuned Stanford Alpaca model weights. The problem? We're not allowed to share the model directly because of some restrictive license on the original LLaMA model. We think that's a dumb rule designed to stifle open-source progress, so we found a way to route around the damage.

The solution was a bit of crypto trickery.
1.  We're not distributing the final model. We're distributing a "patch" file.
2.  If you have the original LLaMA weights (which you obtained legally, of course), our script applies this patch and perfectly reconstructs the Alpaca model on your own machine.
3.  No restricted files are ever hosted on our servers.

The core of this is a simple XOR operation, handled by `encrypt.py` and `decrypt.py` scripts. We even added a checksum to the process to make sure the resulting files are bit-perfect and not corrupted.

The rest of the week was plumbing: setting up the project, writing a basic `chat.py` so you can actually talk to the damn thing, and adding instructions for Windows users.

Frankly, we're not interested in blindly obeying rules that serve no purpose other than to centralize power and slow down innovation. This was a week of principled disobedience for the sake of open AI.
