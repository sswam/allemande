### **More Brains in the Mix, and Making Them Actually Think**

This week we plugged in a couple of new AIs to play with: Grok from xAI and Anthropic's new Claude 3.7 Sonnet. More choice is always better, giving you different "personalities" to bounce ideas off of.

More importantly, we added a "thinking" flag to the system. The idea is to nudge the LLM to do some internal analysis *before* it starts spouting off an answer. The result is fewer glib responses and more insightful replies, which is the whole point.

### **Making AI-Generated Characters Less Random**

Getting a consistent-looking character from an AI artist can be a real pain. Ask for a portrait twice and you'll get two different people. We've started fixing this by giving the AI more specific instructions.

Instead of one big messy visual description, an agent's appearance is now broken down into separate fields: `clothes`, `age`, `emotional_state`, etc. This gives us way more control and results in AI portraits that actually look like the character you're talking to. The system prompt for image generation got a nice tune-up, too.

### **Giving Prompts Some Programming Power**

Static prompts are boring. We've added a few new shortcodes to the Unprompted system that let you build dynamic prompts with simple logic.

Think of it like adding little commands to your text. You can now use things like `[random_number]`, set up weighted choices (`[choose: 70% A | 30% B]`), or even use if/then logic. Itâ€™s a simple way to add variety and unpredictability to AI responses without writing a full script.

### **The Janitorial Work: Webchat Fixes and Cleanup**

A lot of time was also spent on the boring-but-critical stuff.
*   **Webchat:** Fixed annoying bugs with how images load and added better keyboard navigation, so you can now jump between chat rooms using subfolders. A few other small UI tweaks should make things feel smoother.
*   **Code Cleanup:** Did a major pass on refactoring and cleaning up files. All `.yml` config files are now `CamelCase` for consistency, because a messy codebase is a nightmare to maintain. I also improved a few backend scripts to be a bit smarter about what they do and don't touch.
*   **Docs:** Updated the documentation to make it clearer which AI models run online versus offline.
