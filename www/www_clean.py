#!/usr/bin/env python3-allemande

"""
Extract and clean content from HTML pages.
"""

import html
import re
import sys
from typing import TextIO
from bs4 import BeautifulSoup

from ally import main, logs  # type: ignore

__version__ = "0.1.0"

logger = logs.get_logger()


def html_title(ht: str) -> str:
    """ Extract the title from an HTML document """
    if m := re.search(r'<title\b[^>]*>\s*(.*?)\s*</title>', ht, re.IGNORECASE | re.DOTALL):
        title = html.unescape(m[1])
        return title
    return ""


def html_main_content_role_main(ht: str) -> str:
    """ Extract the main content from an HTML page using role='main' """
    parsed_html = BeautifulSoup(ht, "lxml")
    main_element = parsed_html.find_all(role="main")

    if main_element:
        return main_element[0].decode_contents().strip()+"\n"
    return ht


def html_main_content(ht: str) -> str:
    """ Extract the main content from an HTML page """
    # for wikipedia
    if re.search(r'<meta name="generator" content="MediaWiki', ht):
        ht = re.sub(r'\A.*?<div id="bodyContent.*?(<p>)', r'\1', ht, flags=re.DOTALL, count=1)
        ht = re.sub(r'<h2 id="(See_also|References)">.*', r'', ht, flags=re.DOTALL, count=1)
        return ht
    # for pages using <main>
    if m := re.search(r'<main\b[^>]*>\s*(.*?)\s*</main>', ht, re.IGNORECASE | re.DOTALL):
        ht = m[1]
    # for pages using role="main"
    elif re.search(r"""<\w+[^>]*?\brole=['"]?\bmain\b[^>]*>""", ht):
        parsed_html = BeautifulSoup(ht, "lxml")
        if main := parsed_html.find(role="main"):
            ht = main.decode_contents().strip()
    # for pages using <article>
    if m := re.search(r'<article\b[^>]*>\s*(.*?)\s*</article>', ht, re.IGNORECASE | re.DOTALL):
        ht = m[1]
    # kill <nav> elements
    ht = re.sub(r'<nav\b[^>]*>.*?</nav>', '', ht, flags=re.IGNORECASE | re.DOTALL)
    return ht


def pandoc_text_clean(text: str) -> str:
    """ Clean up text generated by pandoc from HTML pages """
    text = re.sub(r'-{4,}', '---', text)    # shorten lines of dashes, e.g. table row lines
    nbsp = "\u00a0"
    text = text.replace(nbsp, " ")    # convert non-breaking space to regular space
    text = re.sub(r'\^\(\[\d+\].*?\)', '', text)    # remove wikipedia cite notes
    text = re.sub(r'[ \t]+', ' ', text)    # remove extra whitespace
    return text


def pandoc_markdown_clean(text: str) -> str:
    """ Clean up markdown generated by pandoc from HTML pages """

    text = re.sub(r'\\$', '', text, flags=re.MULTILINE)    # remove backslash from end of line
    text = re.sub(r'{.*?}', '', text)    # remove pandoc footnotes
    text = re.sub(r'\[(Like|Comment|Most relevant|Share|Log in|Posts|About|Photos|Videos|More)\]', '', text)    # remove facebook buttons
    # text = re.sub(r'\bAll reactions:|### \d+ comments\b|\bSee more\b', '', text)    # remove other facebook guff TODO fix this
    text = re.sub(r'^-? *:::.*', '', text, flags=re.MULTILINE)    # remove pandoc divs
    text = re.sub(r'<.*?>', '', text)    # remove html tags
    text = re.sub(r'!(\[.*?\])?\(.*?\)', '', text)    # remove images
    text = re.sub(r'(https?://\S+?)\?[^\s\)"\']*', r'\1', text)    # remove query strings from urls
    text = re.sub(r'(\(/\S+?)\?[^\s\)"\']*', r'(\1', text)    # remove query strings from relative urls  TODO is this right?
    text = re.sub(r'\((https://www.facebook.com)?/photo/|https://l.facebook.com/l.php\)', '', text)    # remove facebook photos
    text = re.sub(r'\[([^]]+?)\]\(([^)]+?) "([^"]*?)"\)', r'[\1](\2)', text)    # remove markdown link titles

    while re.search(r'\[+[\s\d]*\]+', text):    # remove empty square brackets
        text = re.sub(r'\[+[\s\d]*\]+', '', text)

    text = re.sub(r'[\[\(\{\(\<]+$', '', text, flags=re.MULTILINE)    # remove broken brackets
    text = re.sub(r'^[\]\)\}\>]+', '', text, flags=re.MULTILINE)    # remove broken brackets
    text = re.sub(r'[ \t]+', ' ', text)    # remove extra whitespace
    text = re.sub(r'^ $', '', text, flags=re.MULTILINE)    # remove spaces from empty lines
    text = re.sub(r'-{4,}', '---', text)    # shorten lines of dashes, e.g. table row lines
    text = re.sub(r'_{4,}', '___', text)    # shorten lines of underscores
    text = re.sub(r'={4,}', '===', text)    # shorten lines of equals signs
    text = re.sub(r'^[-_=+:|` ]+$', '', text, flags=re.MULTILINE)    # clear lines that are only drawing horizontal lines and such
    text = re.sub(r'\^?(\[\\\[\s*\d+\s*\\\]\]\(#cite_note[^)]*?\)\s*)+\^?', '', text)    # remove wikipedia cite notes
    text = re.sub(r'\\\[ \[edit\]\(\(/w/index\.php\) \\\]\n\n', '', text)   # remove wikipedia edit links
    text = re.sub(r'^.*?\bdata:image\b.*$', '', text, flags=re.MULTILINE)    # remove lines with data:image, TODO is this okay?

#    text = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', text)    # remove all links

    text = re.sub(r'\n{3,}', '\n\n', text)    # squeeze multiple blank lines
    text = re.sub(r'^\n+', '', text)    # remove leading blank lines
    text = re.sub(r'\n*$', '\n', text, count=1)    # remove trailing blank lines, but have a final newline

    return text


def process_html(istream: TextIO, ostream: TextIO, mode: str = "main") -> None:
    """Process HTML or Text input and output the requested content."""
    content = istream.read()

    if mode == "title":
        result = html_title(content)
    elif mode == "main":
        result = html_main_content(content)
    elif mode == "role-main":
        result = html_main_content_role_main(content)
    elif mode == "text":
        result = pandoc_text_clean(content)
    elif mode == "markdown":
        result = pandoc_markdown_clean(content)
    else:
        logger.error(f"Invalid mode: {mode}")
        sys.exit(1)

    ostream.write(result + "\n")


def setup_args(arg):
    """Set up the command-line arguments."""
    arg("-m", "--mode", choices=["title", "main", "role-main", "text", "markdown"],
        default="main", help="extraction mode")


if __name__ == "__main__":
    main.go(process_html, setup_args)
